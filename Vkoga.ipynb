{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from vkoga_2L import VKOGA_2L\n",
    "from kernels import Matern, Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_samples=500, n_features=3, n_targets=2):\n",
    "    A_true = A_true = np.array([[2, -1, 0.5], [0.5, 1, -0.5], [1, 1, 2]])  # True transformation matrix to calc X and compare later to learned A\n",
    "    X = np.random.randn(n_samples, n_features)\n",
    "    X_transformed = X @ A_true\n",
    "    kernel = Matern(k=2)\n",
    "    K = kernel.eval(X_transformed, X_transformed)\n",
    "    # y = K @ np.random.randn(n_samples, 2)\n",
    "    y = np.dot(X, A_true) + 0.0 * np.random.randn(n_samples, n_features)  # Calculating A with optionally some noise\n",
    "    return X, y, A_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VKOGA_2L model (some Parameters are described in Page 123)\n",
    "model = VKOGA_2L(\n",
    "    kernel=[Matern(k=2), Matern(k=2)], # quadratic Matern kernel used\n",
    "    flag_2L_optimization=True,\n",
    "    verbose=True,\n",
    "    greedy_type='f_greedy',\n",
    "    reg_par=1e-2,\n",
    "    restr_par=1e-2,\n",
    "    tol_f=1e-10,\n",
    "    tol_p=1e-10,\n",
    "    reg_para_optim=0,\n",
    "    learning_rate=5e-3,\n",
    "    n_epochs_optim=100,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "X, y, A_true = generate_data(n_samples=500, n_features=3, n_targets=2)\n",
    "# Split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 3)\n",
      "(400, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leonk\\Desktop\\Uni\\Barb\\Code\\VKOGA\\src\\vkoga\\opt_kernel.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n",
      "C:\\Users\\leonk\\Desktop\\Uni\\Barb\\Code\\VKOGA\\src\\vkoga\\opt_kernel.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5186, -0.2032,  0.2747],\n",
      "        [ 0.2505,  1.0181, -0.3759],\n",
      "        [-0.0625, -0.7332, -2.3227]], requires_grad=True)\n",
      "torch.Size([32, 32])\n",
      "tensor([[3.0000, 1.3825, 0.4589,  ..., 1.6435, 1.4010, 1.6288],\n",
      "        [1.3825, 3.0000, 0.6191,  ..., 1.8334, 2.8295, 0.6055],\n",
      "        [0.4589, 0.6191, 3.0000,  ..., 1.0935, 0.7649, 0.8027],\n",
      "        ...,\n",
      "        [1.6435, 1.8334, 1.0935,  ..., 3.0000, 2.2664, 1.3424],\n",
      "        [1.4010, 2.8295, 0.7649,  ..., 2.2664, 3.0000, 0.7170],\n",
      "        [1.6288, 0.6055, 0.8027,  ..., 1.3424, 0.7170, 3.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Epoch 1/100, Loss: 8946.102142\n",
      "Epoch 2/100, Loss: 8271.230835\n",
      "Epoch 3/100, Loss: 7662.081665\n",
      "Epoch 4/100, Loss: 7110.144226\n",
      "Epoch 5/100, Loss: 6613.167984\n",
      "Epoch 6/100, Loss: 6166.955780\n",
      "Epoch 7/100, Loss: 5766.492142\n",
      "Epoch 8/100, Loss: 5406.710922\n",
      "Epoch 9/100, Loss: 5082.858627\n",
      "Epoch 10/100, Loss: 4790.643723\n",
      "tensor([[ 0.9838, -0.5527,  0.5393],\n",
      "        [ 0.7985,  1.5218, -0.8410],\n",
      "        [ 0.1297, -1.2176, -2.7573]], requires_grad=True)\n",
      "Epoch 11/100, Loss: 4526.268570\n",
      "Epoch 12/100, Loss: 4286.408875\n",
      "Epoch 13/100, Loss: 4068.171204\n",
      "Epoch 14/100, Loss: 3869.046356\n",
      "Epoch 15/100, Loss: 3686.858566\n",
      "Epoch 16/100, Loss: 3519.720047\n",
      "Epoch 17/100, Loss: 3365.991653\n",
      "Epoch 18/100, Loss: 3224.244705"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leonk\\Desktop\\Uni\\Barb\\Code\\VKOGA\\src\\vkoga\\opt_kernel.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X, dtype=torch.float32)\n",
      "C:\\Users\\leonk\\Desktop\\Uni\\Barb\\Code\\VKOGA\\src\\vkoga\\opt_kernel.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Z_tensor = torch.tensor(Z, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19/100, Loss: 3093.234619\n",
      "Epoch 20/100, Loss: 2971.872086\n",
      "tensor([[ 1.2667, -0.8754,  0.8342],\n",
      "        [ 1.2097,  1.8324, -1.1731],\n",
      "        [ 0.2222, -1.6383, -3.0845]], requires_grad=True)\n",
      "Epoch 21/100, Loss: 2859.200974\n",
      "Epoch 22/100, Loss: 2754.382072\n",
      "Epoch 23/100, Loss: 2656.673317\n",
      "Epoch 24/100, Loss: 2565.419685\n",
      "Epoch 25/100, Loss: 2480.039383\n",
      "Epoch 26/100, Loss: 2400.016396\n",
      "Epoch 27/100, Loss: 2324.889893\n",
      "Epoch 28/100, Loss: 2254.248108\n",
      "Epoch 29/100, Loss: 2187.723404\n",
      "Epoch 30/100, Loss: 2124.983803\n",
      "tensor([[ 1.4672, -1.1364,  1.0882],\n",
      "        [ 1.5291,  2.0481, -1.4242],\n",
      "        [ 0.2823, -1.9906, -3.3392]], requires_grad=True)\n",
      "Epoch 31/100, Loss: 2065.731979\n",
      "Epoch 32/100, Loss: 2009.699738\n",
      "Epoch 33/100, Loss: 1956.643890\n",
      "Epoch 34/100, Loss: 1906.344810\n",
      "Epoch 35/100, Loss: 1858.602859\n",
      "Epoch 36/100, Loss: 1813.236267\n",
      "Epoch 37/100, Loss: 1770.080612\n",
      "Epoch 38/100, Loss: 1728.984566\n",
      "Epoch 39/100, Loss: 1689.810730\n",
      "Epoch 40/100, Loss: 1652.432678\n",
      "tensor([[ 1.6251, -1.3563,  1.3064],\n",
      "        [ 1.7926,  2.2116, -1.6252],\n",
      "        [ 0.3309, -2.2932, -3.5463]], requires_grad=True)\n",
      "Epoch 41/100, Loss: 1616.734535\n",
      "Epoch 42/100, Loss: 1582.610413\n",
      "Epoch 43/100, Loss: 1549.962090\n",
      "Epoch 44/100, Loss: 1518.699867\n",
      "Epoch 45/100, Loss: 1488.740067\n",
      "Epoch 46/100, Loss: 1460.006554\n",
      "Epoch 47/100, Loss: 1432.428032\n",
      "Epoch 48/100, Loss: 1405.938553\n",
      "Epoch 49/100, Loss: 1380.477135\n",
      "Epoch 50/100, Loss: 1355.986938\n",
      "tensor([[ 1.7572, -1.5476,  1.4981],\n",
      "        [ 2.0194,  2.3426, -1.7929],\n",
      "        [ 0.3736, -2.5599, -3.7214]], requires_grad=True)\n",
      "Epoch 51/100, Loss: 1332.415367\n",
      "Epoch 52/100, Loss: 1309.713318\n",
      "Epoch 53/100, Loss: 1287.834892\n",
      "Epoch 54/100, Loss: 1266.737843\n",
      "Epoch 55/100, Loss: 1246.381882\n",
      "Epoch 56/100, Loss: 1226.729877\n",
      "Epoch 57/100, Loss: 1207.747250\n",
      "Epoch 58/100, Loss: 1189.401283\n",
      "Epoch 59/100, Loss: 1171.660824\n",
      "Epoch 60/100, Loss: 1154.497906\n",
      "tensor([[ 1.8721, -1.7178,  1.6699],\n",
      "        [ 2.2206,  2.4519, -1.9373],\n",
      "        [ 0.4127, -2.7997, -3.8736]], requires_grad=True)\n",
      "Epoch 61/100, Loss: 1137.885189\n",
      "Epoch 62/100, Loss: 1121.797504\n",
      "Epoch 63/100, Loss: 1106.210659\n",
      "Epoch 64/100, Loss: 1091.102631\n",
      "Epoch 65/100, Loss: 1076.452034\n",
      "Epoch 66/100, Loss: 1062.238537\n",
      "Epoch 67/100, Loss: 1048.443523\n",
      "Epoch 68/100, Loss: 1035.049683\n",
      "Epoch 69/100, Loss: 1022.039856\n",
      "Epoch 70/100, Loss: 1009.397797\n",
      "tensor([[ 1.9745, -1.8719,  1.8266],\n",
      "        [ 2.4029,  2.5458, -2.0645],\n",
      "        [ 0.4492, -3.0190, -4.0091]], requires_grad=True)\n",
      "Epoch 71/100, Loss: 997.108711\n",
      "Epoch 72/100, Loss: 985.158356\n",
      "Epoch 73/100, Loss: 973.533249\n",
      "Epoch 74/100, Loss: 962.220264\n",
      "Epoch 75/100, Loss: 951.207756\n",
      "Epoch 76/100, Loss: 940.483833\n",
      "Epoch 77/100, Loss: 930.036980\n",
      "Epoch 78/100, Loss: 919.857861\n",
      "Epoch 79/100, Loss: 909.935619\n",
      "Epoch 80/100, Loss: 900.261349\n",
      "tensor([[ 2.0676, -2.0134,  1.9713],\n",
      "        [ 2.5709,  2.6283, -2.1786],\n",
      "        [ 0.4838, -3.2221, -4.1317]], requires_grad=True)\n",
      "Epoch 81/100, Loss: 890.825512\n",
      "Epoch 82/100, Loss: 881.620049\n",
      "Epoch 83/100, Loss: 872.636608\n",
      "Epoch 84/100, Loss: 863.867096\n",
      "Epoch 85/100, Loss: 855.304733\n",
      "Epoch 86/100, Loss: 846.941738\n",
      "Epoch 87/100, Loss: 838.771576\n",
      "Epoch 88/100, Loss: 830.787331\n",
      "Epoch 89/100, Loss: 822.983551\n",
      "Epoch 90/100, Loss: 815.353859\n",
      "tensor([[ 2.1534, -2.1448,  2.1063],\n",
      "        [ 2.7276,  2.7020, -2.2824],\n",
      "        [ 0.5169, -3.4124, -4.2443]], requires_grad=True)\n",
      "Epoch 91/100, Loss: 807.892548\n",
      "Epoch 92/100, Loss: 800.594322\n",
      "Epoch 93/100, Loss: 793.453655\n",
      "Epoch 94/100, Loss: 786.466007\n",
      "Epoch 95/100, Loss: 779.626217\n",
      "Epoch 96/100, Loss: 772.929802\n",
      "Epoch 97/100, Loss: 766.372578\n",
      "Epoch 98/100, Loss: 759.949642\n",
      "Epoch 99/100, Loss: 753.657440\n",
      "Epoch 100/100, Loss: 747.492249\n",
      "\n",
      "****************************** [VKOGA] ******************************\n",
      "Training model with\n",
      "       |_ kernel              : mat2 [gamma = 1.00e+00]\n",
      "       |_ regularization par. : 1.00e-02\n",
      "       |_ restriction par.    : 0.00e+00\n",
      "\n",
      "Training ongoing with\n",
      "       |_ selected points     :        1 /      100\n",
      "       |_ train residual      : 8.44e+01 / 1.00e-10\n",
      "       |_ train power fun     : 3.01e+00 / 1.00e-10\n",
      "Training ongoing with\n",
      "       |_ selected points     :       11 /      100\n",
      "       |_ train residual      : 3.86e+01 / 1.00e-10\n",
      "       |_ train power fun     : 3.01e+00 / 1.00e-10\n",
      "Training ongoing with\n",
      "       |_ selected points     :       21 /      100\n",
      "       |_ train residual      : 2.74e+01 / 1.00e-10\n",
      "       |_ train power fun     : 3.01e+00 / 1.00e-10\n",
      "Training ongoing with\n",
      "       |_ selected points     :       31 /      100\n",
      "       |_ train residual      : 1.94e+01 / 1.00e-10\n",
      "       |_ train power fun     : 3.01e+00 / 1.00e-10\n",
      "Training ongoing with\n",
      "       |_ selected points     :       41 /      100\n",
      "       |_ train residual      : 1.26e+01 / 1.00e-10\n",
      "       |_ train power fun     : 3.01e+00 / 1.00e-10\n",
      "Training ongoing with\n",
      "       |_ selected points     :       51 /      100\n",
      "       |_ train residual      : 9.44e+00 / 1.00e-10\n",
      "       |_ train power fun     : 3.01e+00 / 1.00e-10\n",
      "Training ongoing with\n",
      "       |_ selected points     :       61 /      100\n",
      "       |_ train residual      : 5.49e+00 / 1.00e-10\n",
      "       |_ train power fun     : 3.01e+00 / 1.00e-10\n",
      "Training ongoing with\n",
      "       |_ selected points     :       71 /      100\n",
      "       |_ train residual      : 3.66e+00 / 1.00e-10\n",
      "       |_ train power fun     : 3.00e+00 / 1.00e-10\n",
      "Training ongoing with\n",
      "       |_ selected points     :       81 /      100\n",
      "       |_ train residual      : 2.14e+00 / 1.00e-10\n",
      "       |_ train power fun     : 2.98e+00 / 1.00e-10\n",
      "Training ongoing with\n",
      "       |_ selected points     :       91 /      100\n",
      "       |_ train residual      : 1.49e+00 / 1.00e-10\n",
      "       |_ train power fun     : 2.97e+00 / 1.00e-10\n",
      "Training completed with\n",
      "       |_ selected points     :      100 /      100\n",
      "       |_ train residual      : 8.78e-01 / 1.00e-10\n",
      "       |_ train power fun     : 2.94e+00 / 1.00e-10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VKOGA_2L(flag_2L_optimization=True,\n",
       "         kernel=<kernels.Matern object at 0x000002197DC79910>,\n",
       "         n_epochs_optim=100, reg_par=0.01, reg_para_optim=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[-1.84927299  0.13383716 -2.19416916]\n",
      " [ 2.34980915  0.00290556 -0.81797546]\n",
      " [-2.37478671 -1.17342028 -0.44658202]\n",
      " [ 0.47326137  1.28914008  0.85147792]\n",
      " [-0.49125884  2.88072599  1.02500689]]\n",
      "Ground truth: [[-1.89497628  0.12015473 -2.3318907 ]\n",
      " [ 2.35952967  0.03464933 -0.93687022]\n",
      " [-2.7452759  -1.2277997  -0.32934575]\n",
      " [ 0.5376046   1.86692396  1.14995049]\n",
      " [-0.42373227  2.9105026   1.03758427]]\n"
     ]
    }
   ],
   "source": [
    "# Print the first few predictions and ground truth\n",
    "print(\"Predictions:\", predictions[:5])\n",
    "print(\"Ground truth:\", y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Data: 0.418063\n"
     ]
    }
   ],
   "source": [
    "# MSE\n",
    "mse = np.mean((predictions - y_test) ** 2)\n",
    "print(f\"Mean Squared Error on Test Data: {mse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learned A:\n",
      "[[ 2.233441  -2.2678554  2.2335498]\n",
      " [ 2.8753164  2.768862  -2.3779266]\n",
      " [ 0.548826  -3.5922155 -4.3489633]]\n",
      "true A:\n",
      "[[ 2.  -1.   0.5]\n",
      " [ 0.5  1.  -0.5]\n",
      " [ 1.   1.   2. ]]\n"
     ]
    }
   ],
   "source": [
    "# Compare Learnend and original A\n",
    "print(\"learned A:\")\n",
    "print(model.A)\n",
    "print(\"true A:\")\n",
    "print(A_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
